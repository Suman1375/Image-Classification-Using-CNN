# -*- coding: utf-8 -*-
"""Image Classification using CNN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sfz0wcSk_BdK6cOBApj9zl7n7vo2ilJ5

# Image Classification (CATS vs DOGS)
"""

import tensorflow as tf

from keras.preprocessing.image import ImageDataGenerator
batch_size = 64
input_size=(128,128)
train_datagen = ImageDataGenerator(rescale = 1./255,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True)

test_datagen = ImageDataGenerator(rescale = 1./255)

training_set = train_datagen.flow_from_directory('/content/dataset/training_set',
                                                 target_size = input_size,
                                                 batch_size = batch_size,
                                                 class_mode = 'binary')

test_set = test_datagen.flow_from_directory('/content/dataset/test_set',
                                            target_size = input_size,
                                            batch_size = batch_size,
                                            class_mode = 'binary',
                                            shuffle=False)

"""MODEL 1 :"""

from keras import layers

model1 = tf.keras.models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128,128,3)),
    layers.MaxPooling2D(2, 2),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),

    layers.Flatten(),
    layers.Dense(512, activation='relu'),
    layers.BatchNormalization(),
    layers.Dense(512, activation='relu'),
    layers.Dropout(0.1),
    layers.BatchNormalization(),
    layers.Dense(512, activation='relu'),
    layers.Dropout(0.2),
    layers.BatchNormalization(),
    layers.Dense(1, activation='sigmoid')
])

model1.summary()

tf.keras.utils.plot_model(model1, show_shapes=True,show_layer_activations=True,to_file='model1.png')

model1.compile(
    loss='binary_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

model1.fit(training_set,
          steps_per_epoch = 8000/batch_size,
          epochs = 10,
          validation_data = test_set,
          validation_steps = 2000/batch_size)

model1.save('model1.keras')

"""MODEL 2:"""

model2 = tf.keras.models.Sequential()
input_size = (128, 128)
model2.add(tf.keras.layers.Convolution2D(32, 3, 3, input_shape = (*input_size, 3), activation = 'relu'))
model2.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))
model2.add(tf.keras.layers.Convolution2D(32, 3, 3, activation = 'relu'))
model2.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))
model2.add(tf.keras.layers.Flatten())
model2.add(tf.keras.layers.Dense(units = 64, activation = 'relu'))
model2.add(tf.keras.layers.Dropout(0.5))
model2.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))
model2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

print(model2.summary())

tf.keras.utils.plot_model(model2, show_shapes=True,show_layer_activations=True,to_file='model2.png')

model2.fit(training_set,
          steps_per_epoch = 8000/batch_size,
          epochs = 10,
          validation_data = test_set,
          validation_steps = 2000/batch_size)

model2.save('model2.keras')

"""MODEL 3:"""

model3 = tf.keras.models.Sequential()

model3.add(tf.keras.layers.Convolution2D(64, 3, 3, input_shape=(*input_size, 3), activation='relu'))
model3.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))

model3.add(tf.keras.layers.Convolution2D(64, 3, 3, activation='relu'))
model3.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))


model3.add(tf.keras.layers.Flatten())

model3.add(tf.keras.layers.Dense(units=128, activation='relu'))
model3.add(tf.keras.layers.Dropout(0.5))

model3.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))

model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model3.summary()

tf.keras.utils.plot_model(model3, show_shapes=True,show_layer_activations=True,to_file='model3.png')

model3.fit(training_set,
          steps_per_epoch = 8000/batch_size,
          epochs = 10,
          validation_data = test_set,
          validation_steps = 2000/batch_size)

model3.save('model3.keras')

"""MODEL 4:"""

from tensorflow.keras.applications import VGG16
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np

base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))

for layer in base_model.layers:
    layer.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(256, activation='relu')(x)
predictions = Dense(1, activation='sigmoid')(x)

model = Model(inputs=base_model.input, outputs=predictions)


model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])

print(model.summary())

model.fit(training_set,
          steps_per_epoch = 8000/batch_size,
          epochs = 5,
          validation_data = test_set,
          validation_steps = 2000/batch_size)

model.save('model4.keras')

"""CONFUSION MATRIX"""

model1 = tf.keras.models.load_model('model1.keras')
model2 = tf.keras.models.load_model('model2.keras')
model3 = tf.keras.models.load_model('model3.keras')
model4 = tf.keras.models.load_model('model4.keras')

from sklearn.metrics import confusion_matrix
import numpy as np

predictions1 = model1.predict(test_set, steps=len(test_set), verbose=1)
predicted_classes1 = (predictions1 > 0.5).astype(int)

predictions2 = model2.predict(test_set, steps=len(test_set), verbose=1)
predicted_classes2 = (predictions2 > 0.5).astype(int)

predictions3 = model3.predict(test_set, steps=len(test_set), verbose=1)
predicted_classes3 = (predictions3 > 0.5).astype(int)

predictions4 = model4.predict(test_set, steps=len(test_set), verbose=1)
predicted_classes4 = (predictions4 > 0.5).astype(int)

true_labels = test_set.classes

# Confusion Matrix
conf_matrix1 = confusion_matrix(true_labels, predicted_classes1)
conf_matrix2 = confusion_matrix(true_labels, predicted_classes2)
conf_matrix3 = confusion_matrix(true_labels, predicted_classes3)
conf_matrix4 = confusion_matrix(true_labels, predicted_classes4)


print("Confusion Matrix for Model 1:")
print(conf_matrix1)
print("===================================")
print("Confusion Matrix for Model 2:")
print(conf_matrix2)
print("===================================")
print("Confusion Matrix for Model 3:")
print(conf_matrix3)
print("===================================")
print("Confusion Matrix for Model 4:")
print(conf_matrix4)

from prettytable import PrettyTable


model1_conf_matrix = conf_matrix1
model2_conf_matrix = conf_matrix2
model3_conf_matrix = conf_matrix3
model4_conf_matrix = conf_matrix4


def calculate_metrics(conf_matrix):
    tp, fp, fn, tn = conf_matrix[0][0], conf_matrix[0][1], conf_matrix[1][0], conf_matrix[1][1]
    accuracy = (tp + tn) / sum(sum(conf_matrix))
    precision = tp / (tp + fp)
    recall = tp / (tp + fn)
    f1_score = 2 * (precision * recall) / (precision + recall)
    selectivity = tn / (tn + fp)
    negative_predictive_value = tn / (tn + fn)
    miss_rate = fn / (fn + tp)
    fall_out = fp / (fp + tn)
    false_discovery_rate = fp / (fp + tp)
    false_omission_rate = fn / (fn + tn)
    positive_likelihood_ratio = recall / fall_out
    negative_likelihood_ratio = miss_rate / selectivity
    balance_accuracy = (recall + selectivity) / 2
    threat_score = tp / (tp + fp + fn)
    return accuracy, precision, recall, f1_score, selectivity, negative_predictive_value, miss_rate, fall_out, false_discovery_rate, false_omission_rate, positive_likelihood_ratio, negative_likelihood_ratio, balance_accuracy, threat_score


table = PrettyTable()
table.field_names = ["Model", "Accuracy", "Precision", "Recall", "F1 Score", "Selectivity", "Negative Predictive Value", "Miss Rate", "Fall Out", "False Discovery Rate", "False Omission Rate", "Positive Likelihood Ratio", "Negative Likelihood Ratio", "Balance Accuracy", "Threat Score"]

for model_name, conf_matrix in zip(["Model 1", "Model 2", "Model 3","Model 4"], [model1_conf_matrix, model2_conf_matrix, model3_conf_matrix,model4_conf_matrix]):
    accuracy, precision, recall, f1_score, selectivity, negative_predictive_value, miss_rate, fall_out, false_discovery_rate, false_omission_rate, positive_likelihood_ratio, negative_likelihood_ratio, balance_accuracy, threat_score = calculate_metrics(conf_matrix)
    table.add_row([model_name, f"{accuracy:.2f}", f"{precision:.2f}", f"{recall:.2f}", f"{f1_score:.2f}", f"{selectivity:.2f}", f"{negative_predictive_value:.2f}", f"{miss_rate:.2f}", f"{fall_out:.2f}", f"{false_discovery_rate:.2f}", f"{false_omission_rate:.2f}", f"{positive_likelihood_ratio:.2f}", f"{negative_likelihood_ratio:.2f}", f"{balance_accuracy:.2f}", f"{threat_score:.2f}"])

print(table)

